# N-word-frequency

C++ programs used to generate N-word-frequency database from the <a href="https://books.google.com/ngrams">Google Books Ngram Corpus</a>.


# Requirements

## Download N-gram Google Books

First, download <a href="http://storage.googleapis.com/books/ngrams/books/datasetsv2.html">The Google Books Ngram Corpus</a> you need (with the corresponding totalcounts file) and put all the files in a directory, by number of ngram. For example, if you download the English 2grams, the English 3grams, and the French 2grams corpora, make sure to have a directory for each corpora.
If you use MacOS, you can download them with -- --.

## On Windows 10

The programs work on a Linux environment. You can install a <a href="https://www.virtualbox.org/wiki/Downloads">virtual machine</a> to use Ubuntu for example, or you can install Ubuntu Bash.

Installing Ubuntu Bash:
1. You need to have a Build version greater than 14393 and Windows 10 64-bits. !!Image ici!!
2. Open Settings app and go to Update & Security -> For Developers and choose the “Developer Mode” radio button.
3. Go to the Control Panel -> Programs and click “Turn Windows feature on or off”. Enable “Windows Subsystem for Linux(Beta)”. When you click OK, you will be prompted to reboot. Click “Restart Now” to reboot your PC.
4. Open the Microsoft Store, search "Ubuntu 18.04 LTS" and download it. 
5. Open the Ubuntu 18.04 terminal, enter an user name and a password.

The `C:\` drive is mounted as `/mnt/c/`, `D:\` is mounted as `/mnt/d/`, etc. To access your Documents, you can type `cd /mnt/c/Users/your_name/Documents/` by replacing your_name by your user name.
You can now read the "On Linux" part to complete others installations.

## On Linux

-S'il y a des problèmes de fichier les mettre en format unix:  sudo apt-get install dos2unix puis dos2unix nom_fichier -

1. Open a terminal.
2. Run `sudo apt-get update`
3. Install g++ `sudo apt-get install g++`
4. Install make `sudo apt-get install make`
5. <a href="https://zlib.net/zlib1211.zip">Download zlib</a> and extract it to the same programs repository (zlib's extracted directory have to be in this github repository).
6. Go to the zlib directory and run ./configure: `cd zlib1211/zlib-1.2.11/` and `./configure`
7. Run `sudo make install`
8. `cd ../..` and `sudo chmod 777 make_all.sh`
9. `./make_all.sh`

## On MacOS

--todo - surement pareil que sur linux--


# How to use the different programs
For each programs, there are a multithreading and a non-multithreading version. Multithreading is used to reduce computation time. We recommand to use the multithreading version if there are a lot of files to process.

## a_generate_files
From .gz files, it generates ngrams files containing for each unique ngram its  :
* number of years
* total occurrence through the years
* number of volume through the years
* mean year ponderated by the total of occurrences
* mean year ponderated by the number of volumes
* year max
* year min
* occurence max
* occurence min
* number of volume max
* number of volume min

\tTake into account only ngrams with words tagged with :\n\
\tNOUN, VERB, ADJ, ADV, PRON, DET, ADP, CONJ, PRT and words different \
than:\n\t',', '.', '?', '!', '...', ';', ':', '\"', ' ', '''\n\n"

Put in the config file :
<pre><code>
a_generate_file:
path_to_gz_files = /path_to_the_googlebooks_ngram_corpus_gz_files/
path_to_output_files = /path_to_where_you_want_the_output_files/
nb_ngram = number of ngram in the .gz files
min_year = the minimum year you want
no_number = 1 if you don't want numerical word like 1, 2, etc (but take into account "one", "two", etc), else 0.
END
</code></pre>

Example with Ubuntu Bash on Windows 10 :
<pre><code>
a_generate_file:
path_to_gz_files = /mnt/c/Users/Me/Documents/N-word-frequency/files_fr_2grams/
path_to_output_files = /mnt/c/Users/Me/Documents/N-word-frequency/files_fr_2grams/
nb_ngram = 2
min_year = 1970
no_number = 1
END
</code></pre>

Then run `a_generate_files/./generate_treated_files_thread config.ini > log_a_generate_file.txt`. 
The `> log_a_generate_file.txt` part is used to write what the program do in the file log_a_generate_file.txt (if the file doesn't exist, it will be created) in addition to writing into the terminal. Of course you can named this file how you want. 

## b_calcul_total_occurrences

Uses the files generated by a_generate_files to compute the total number of ngrams (sum of all unique ngrams' occurrence). Read the total number of volumes with the totalcounts file. Writes these two numbers in a file.

Put in the config file :
<pre><code>
b_calcul_total_occurrences:
output_file_name = file name
totalcount_file = find your totalcount file <a href="http://storage.googleapis.com/books/ngrams/books/datasetsv2.html">here</a>
path_to_treated_files = /path_to_the_files_generated_by_a_generate_files_directory/
min_year = the minimum year you want
nb_ngram = number of ngram in the files generated by a_generate_files
END
</code></pre>

Example with Ubuntu Bash on Windows 10 :
<pre><code>
b_calcul_total_occurrences:
output_file_name = /mnt/c/Users/Me/Documents/N-word-frequency/files_fr_2grams/total_occurrences_fr_2grams.txt
totalcount_file = /mnt/c/Users/Me/Documents/N-word-frequency/files_fr_2grams/googlebooks-fre-all-totalcounts-20120701.txt
path_to_treated_files = /mnt/c/Users/Me/Documents/N-word-frequency/files_fr_2grams/
min_year = 1970
nb_ngram = 2
END
</code></pre>

Then run `b_calcul_total_occurrences/./calcul_occurences_thread config.ini > log_b_calcul_occurrences.txt`.
The `> log_b_calcul_occurrences.txt` part is used to write what the program do in the file log_b_calcul_occurrences.txt (if the file doesn't exist, it will be created) in addition to writing into the terminal. Of course you can named this file how you want. 

## c_calcul_frequences

Compute the frequence of each unique ngram generated by a_generate_files, thanks to the file generated by b_calcul_total_occurrences.

Put in the config file :
<pre><code>
c_calcul_frequences:
total_occurrences_files = file generated by b_calcul_total_occurrences
path_to_treated_files = /path_to_the_files_generated_by_a_generate_files_directory/
path_to_output_files = /path_to_where_you_want_the_output_files/
nb_ngram = number of ngram in the files generated by a_generate_files
END
</code></pre>

Example with Ubuntu Bash on Windows 10 :
<pre><code>
c_calcul_frequences:
total_occurrences_files = /mnt/c/Users/Me/Documents/N-word-frequency/files_fr_2grams/total_occurrences_fr_2grams.txt
path_to_treated_files = /mnt/c/Users/Me/Documents/N-word-frequency/files_fr_2grams/
path_to_output_files = /mnt/c/Users/Me/Documents/N-word-frequency/files_fr_2grams/
nb_ngram = 2
END
</code></pre>

## d_calcul_frequences_tag_grams

Compute the frequence of each tag-grams from the Google Books Ngram Corpus .gz files. They are named \_ADJ\_, \_ADP\_, \_ADV\_, \_CONJ\_, \_DET\_, \_NOUN\_, \_PRON\_, \_PRT\_, \_VERB\_. Put them all in the same directory. The output file is a .csv containing, for each tag-gram :
* number of years
* total occurrence through the years
* number of volume through the years
* mean year ponderated by the total of occurrences
* mean year ponderated by the number of volumes
* year max
* year min
* occurence max
* occurence min
* number of volume max
* number of volume min
* total occurrence's frequence
* number of volume's frequence

Put in the config file :
<pre><code>
d_calcul_frequences_tag_grams:
output_file_name = file name
totalcount_file = find your totalcount file <a href="http://storage.googleapis.com/books/ngrams/books/datasetsv2.html">here</a>
path_to_gz_pos_files = /path_to_the_googlebooks_ngram_corpus_part_of_speech_gz_files/
nb_ngram = number of ngram in the files generated by a_generate_files
min_year = the minimum year you want
END
</code></pre>

Example with Ubuntu Bash on Windows 10 :
<pre><code>
d_calcul_frequences_tag_grams:
output_file_name = /mnt/c/Users/Me/Documents/N-word-frequency/files_fr_2grams/tag_gram_fr_2grams.csv
totalcount_file = /mnt/c/Users/Me/Documents/N-word-frequency/files_fr_2grams/googlebooks-fre-all-totalcounts-20120701.txt
path_to_gz_pos_files = /mnt/c/Users/Me/Documents/N-word-frequency/files_fr_2grams/pos/
nb_ngram = 2
min_year = 1970
END
</code></pre>